{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc55903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae10a6b",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Для данных о погоде создать категорию \"время года\" и закодировать ее при помощи OneHotEncoder. Проще всего применить OneHotEncoder при помощи `pandas.get_dummies()`\n",
    "\n",
    "Преобразовать данные о температуре двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27ae38db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>autumn</th>\n",
       "      <th>spring</th>\n",
       "      <th>summer</th>\n",
       "      <th>winter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>-11</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-05</th>\n",
       "      <td>-12</td>\n",
       "      <td>1</td>\n",
       "      <td>winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             t  month  season  autumn  spring  summer  winter\n",
       "Day                                                          \n",
       "2008-01-01   0      1  winter       0       0       0       1\n",
       "2008-01-02  -5      1  winter       0       0       0       1\n",
       "2008-01-03 -11      1  winter       0       0       0       1\n",
       "2008-01-04 -11      1  winter       0       0       0       1\n",
       "2008-01-05 -12      1  winter       0       0       0       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/weather.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "mapper = {\n",
    "    1: 'winter',\n",
    "    2: 'winter',\n",
    "    3: 'spring',\n",
    "    4: 'spring',\n",
    "    5: 'spring',\n",
    "    6: 'summer',\n",
    "    7: 'summer',\n",
    "    8: 'summer',\n",
    "    9: 'autumn',\n",
    "    10: 'autumn',\n",
    "    11: 'autumn',\n",
    "    12: 'winter'\n",
    "}\n",
    "\n",
    "df['month'] = df.index.month\n",
    "df['season'] = df['month'].map(mapper)\n",
    "pd.concat([df, pd.get_dummies(df['season'])], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0652fa57",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Перебрать параметры `n_estimators`, `criterion` и `max_depth` и найти оптимальные. \n",
    "\n",
    "Для решения можно написать тройной цикл, в каждом из которых можно перебирать значения параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9d5d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()\n",
    "x = data.data\n",
    "y = data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73acc583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_of_model(x_train, y_train, x_test, y_test, n_estimators, criterion, max_depth):\n",
    "    \"\"\"Функция принимает на вход треин и тест выборки и параметры модели. На выходе дает accuracy.\"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418096f",
   "metadata": {},
   "source": [
    "**Вариант 1. Перебираем в тройном цикле**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a444442f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, (100, 'entropy', 10))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [5, 100, 300, 500]\n",
    "criterions = ['gini', 'entropy']\n",
    "max_depths = [3, 5, 7, 10]\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "# Ваш код здесь\n",
    "for n in n_estimators:\n",
    "    for criterion in criterions:\n",
    "        for max_depth in max_depths:\n",
    "            acc = get_accuracy_of_model(x_train, y_train, x_test, y_test, n, criterion, max_depth)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_params = (n, criterion, max_depth)\n",
    "\n",
    "best_acc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b209af",
   "metadata": {},
   "source": [
    "**Вариант 2. Генерируем сетку и перебираем по ней**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56d0a69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, (100, 'entropy', 10))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "best_acc = 0\n",
    "best_params = None\n",
    "for (n, criretion, max_depth) in itertools.product(n_estimators, criterions, max_depths):\n",
    "    acc = get_accuracy_of_model(x_train, y_train, x_test, y_test, n, criterion, max_depth)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = (n, criterion, max_depth)\n",
    "        \n",
    "best_acc, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02cbb2",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Построить модель SGDClassifier и осуществить подбор гиперпараметров при помощи случайного поиска (список гиперпараметров можно посмотреть в документации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf3bf44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, max_iter=100, penalty='elasticnet')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.00001, 0.0001, 0.1],\n",
    "    'max_iter': [100, 1000, 2000],\n",
    "    'eta0': [0, 0.1, 0.0001]\n",
    "}\n",
    "\n",
    "r_search = RandomizedSearchCV(SGDClassifier(), params)\n",
    "r_search.fit(x_train, y_train)\n",
    "r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14200b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547046674927715"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf3a556",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Обучить модель градиентного бустинга на датасете, провести подбор гиперпараметров (взять любые 3 штуки, их список можно получить через документацию к модели).\n",
    "\n",
    "Сравнить качество с полученными ранее результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "375f3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 10 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\koval\\anaconda3\\envs\\data-science-class\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.44839047 0.10839047        nan        nan 0.9494947\n",
      " 0.96435633        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [0.0001, 0.00001, 0.0001, 0.1],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [2, 3, 5]\n",
    "}\n",
    "\n",
    "r_search = RandomizedSearchCV(GradientBoostingClassifier(), params)\n",
    "r_search.fit(x_train, y_train)\n",
    "r_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8175010",
   "metadata": {},
   "source": [
    "В warning сказано, что 30 из 50 моделей не смогли обучиться, потому что лосс-функция `exponential` работает только с бинарной классификацией. Можно убрать подбор по лоссу, и тогда отработает быстрее и качественнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f99100c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9643563265868099"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab6c4b",
   "metadata": {},
   "source": [
    "## Задача\n",
    "\n",
    "Иногда нужно использовать модели, у которых интерфейс отличается от интерфейса моделей из sklearn и тогда приходится самостоятельно реализовывать стекинг.\n",
    "\n",
    "Задача \n",
    "\n",
    "Алгоритм построения стекинга:\n",
    "- Получить прогнозы базовых моделей\n",
    "- Использовать прогнозы базовых моделей в качестве признаков для финализирующей модели\n",
    "- Оформить модель в отдельную функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e07e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9919686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(x_train, y_train, models):\n",
    "    \"\"\"Обучаем модели\"\"\"\n",
    "    for model in models:\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "def predict_base_models(x, models):\n",
    "    \"\"\"Предсказываем и нормируем прогнозы\"\"\"\n",
    "    res = []\n",
    "    for model in models:\n",
    "        res.append(model.predict(x))\n",
    "    base_predictions = np.array(res).T\n",
    "    # Некоторые модели чувствительны к тому, чтобы на входе были нормированные данные\n",
    "    return preprocess_data(base_predictions)\n",
    "\n",
    "def predict_proba_base_models(x, models):\n",
    "    \"\"\"Предсказываем через predict_proba (у меня результат получался хуже на этих данных)\"\"\"\n",
    "    res = np.array([])\n",
    "    for model in models:\n",
    "        if len(res) == 0:\n",
    "            res = model.predict_proba(x)\n",
    "        else:\n",
    "            res = np.hstack((res, model.predict_proba(x)))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e182bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stacking(x_train, y_train, models, final_model):\n",
    "    fit_models(x_train, y_train, models)\n",
    "    final_features = predict_base_models(x_train, models)\n",
    "    final_model.fit(final_features, y_train)\n",
    "    return models, final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c19fed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stacking(x, models, final_model):\n",
    "    final_features = predict_base_models(x, models)\n",
    "    return final_model.predict(final_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28089e",
   "metadata": {},
   "source": [
    "Для лучшей сходимости методов преобразуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27bb8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717d225",
   "metadata": {},
   "source": [
    "Используем модели из предыдущих заданий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "797ccd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем модели\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=500, criterion='entropy', max_depth=7),\n",
    "    LogisticRegression(penalty='elasticnet', max_iter=1000, solver='saga', l1_ratio=0.5)\n",
    "]\n",
    "final_model = DecisionTreeClassifier(max_depth=12)\n",
    "\n",
    "# Обучаем стекинг\n",
    "models, final_model = fit_stacking(x_train, y_train, models, final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9247b2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755555555555555"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict_stacking(x_test, models, final_model)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0edd60",
   "metadata": {},
   "source": [
    "Точность немного выше, чем было до этого"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
